name: Database Backup

on:
  schedule:
    - cron: '0 3 * * *'  # Daily at 3 AM
  workflow_dispatch:  # Manual trigger

permissions:
  contents: read
  issues: write

jobs:
  backup:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create backup
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}
        BACKUP_BUCKET: ${{ secrets.BACKUP_BUCKET }}
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      run: |
        # Create backup directory
        mkdir -p backups
        
        # Generate backup filename with timestamp
        BACKUP_FILE="backup-$(date +%Y%m%d-%H%M%S).sql"
        
        # Create database backup (if using PostgreSQL)
        if [[ $DATABASE_URL == postgresql://* ]]; then
          # Extract database connection details
          DB_URL=$(echo $DATABASE_URL | sed 's/postgresql:\/\///')
          DB_HOST=$(echo $DB_URL | cut -d'@' -f2 | cut -d':' -f1)
          DB_PORT=$(echo $DB_URL | cut -d'@' -f2 | cut -d':' -f2 | cut -d'/' -f1)
          DB_NAME=$(echo $DB_URL | cut -d'/' -f2)
          DB_USER=$(echo $DB_URL | cut -d'@' -f1 | cut -d':' -f1)
          DB_PASS=$(echo $DB_URL | cut -d'@' -f1 | cut -d':' -f2)
          
          # Install PostgreSQL client
          sudo apt-get update
          sudo apt-get install -y postgresql-client
          
          # Create backup
          PGPASSWORD=$DB_PASS pg_dump -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME > backups/$BACKUP_FILE
          
          echo "Backup created: backups/$BACKUP_FILE"
        else
          echo "Database backup not configured for this database type"
          exit 0
        fi
    
    - name: Upload backup to S3
      if: env.BACKUP_BUCKET != ''
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        BACKUP_BUCKET: ${{ secrets.BACKUP_BUCKET }}
      run: |
        # Install AWS CLI
        curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
        unzip awscliv2.zip
        sudo ./aws/install
        
        # Upload backup to S3
        aws s3 cp backups/*.sql s3://$BACKUP_BUCKET/backups/
        
        # Clean up old backups (keep last 7 days)
        aws s3 ls s3://$BACKUP_BUCKET/backups/ | sort -r | tail -n +8 | awk '{print $4}' | xargs -I {} aws s3 rm s3://$BACKUP_BUCKET/backups/{}
    
    - name: Upload backup as artifact
      uses: actions/upload-artifact@v4
      with:
        name: database-backup
        path: backups/
        retention-days: 7
    
    - name: Notify on failure
      if: failure()
      uses: actions/github-script@v7
      with:
        script: |
          try {
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'ðŸš¨ Database Backup Failed',
              body: 'The scheduled database backup failed. Please check the logs.',
              labels: ['backup', 'urgent']
            });
          } catch (error) {
            console.log('Failed to create issue:', error.message);
          }
